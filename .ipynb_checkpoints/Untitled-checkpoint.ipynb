{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17497740",
   "metadata": {},
   "source": [
    "Importing the necessary Libraries for the Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96caeacd-90f4-41e3-9534-5e62c56ac759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ee3417",
   "metadata": {},
   "source": [
    "Function for loading the Images from The datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd60f54d-6070-477e-84b7-daa8bb7ccbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  def load_metadata(meta_folder, image_folder):\n",
    "#     pairs = []\n",
    "#     labels = []\n",
    "#     for mat_file in os.listdir(meta_folder):\n",
    "#         mat_path = os.path.join(meta_folder, mat_file)\n",
    "#         data = loadmat(mat_path)['pairs']\n",
    "#         for pair in data:\n",
    "#             img1 = os.path.join(image_folder, '**',str (pair[0][0]))\n",
    "#             img2 = os.path.join(image_folder, '**',str(pair[1][0]))\n",
    "#             label = pair[2][0][0]  # 1 for similar, 0 for dissimilar\n",
    "\n",
    "#             img1_path = glob.glob(img1, recursive=True)[0] \n",
    "#             img2_path = glob.glob(img2, recursive=True)[0]\n",
    "#             pairs.append((img1_path, img2_path))\n",
    "#             labels.append(label)\n",
    "#     return pairs, labels\n",
    "def load_metadata(meta_data_path, image_folder):\n",
    "     \"\"\" Loads pairs and labels directly from the metadata folder (.mat files). \"\"\" \n",
    "     pairs = []\n",
    "     labels = [] # Iterate over each subfolder in the image folder \n",
    "     for relation_folder in os.listdir(image_folder): \n",
    "        relation_path = os.path.join(image_folder, relation_folder)\n",
    "        if not os.path.isdir(relation_path):\n",
    "             continue # Corresponding .mat file\n",
    "             mat_file = os.path.join(meta_data_path, f\"{relation_folder}.mat\") \n",
    "             if os.path.exists(mat_file):\n",
    "                 data = loadmat(mat_file)['pairs']\n",
    "                 for pair in data:\n",
    "                  img1 = os.path.join(relation_path, str(pair[2][0]))\n",
    "                  img2 = os.path.join(relation_path, str(pair[3][0]))\n",
    "                  label = pair[1][0] # 1 for similar, 0 for dissimilar # Ensure images exist \n",
    "                  if os.path.exists(img1) and os.path.exists(img2):\n",
    "                     pairs.append((img1, img2))\n",
    "                     labels.append(label)\n",
    "                  else:\n",
    "                     print(f\"Image paths not found for: {img1} or {img2}\") \n",
    "                     return pairs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb79fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    image=cv.imread(img_path)\n",
    "    image_resized = cv.resize(image, (224, 224))\n",
    "    image_normalized = image_resized / 255.0 \n",
    "    image_transposed = np.transpose(image_normalized, (2, 0, 1)) #As pytorch prefers the image tensore in form of (Chnnel, Height, Width)\n",
    "    return torch.tensor(image_transposed, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4971656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadmat_data(meta_folder, image_folder):\n",
    "    pairs,labels = load_metadata(meta_folder, image_folder)\n",
    "    preprocessed_pairs=[]\n",
    "    for img1_path, img2_path in pairs:\n",
    "        img1 = preprocess_image(img1_path)\n",
    "        img2 = preprocess_image(img2_path)\n",
    "        preprocessed_pairs.append((img1, img2))\n",
    "    return preprocessed_pairs,torch.tensor(labels, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b92c66c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m meta_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSNN project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mKinFaceW-II\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmeta_data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSNN project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mKinFaceW-II\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m preprocessed_pairs, labels \u001b[38;5;241m=\u001b[39m \u001b[43mloadmat_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of pairs loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(preprocessed_pairs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n",
      "Cell \u001b[1;32mIn[62], line 2\u001b[0m, in \u001b[0;36mloadmat_data\u001b[1;34m(meta_folder, image_folder)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloadmat_data\u001b[39m(meta_folder, image_folder):\n\u001b[1;32m----> 2\u001b[0m     pairs,labels \u001b[38;5;241m=\u001b[39m load_metadata(meta_folder, image_folder)\n\u001b[0;32m      3\u001b[0m     preprocessed_pairs\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m img1_path, img2_path \u001b[38;5;129;01min\u001b[39;00m pairs:\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "meta_folder = r\"E:\\SNN project\\data\\KinFaceW-II\\meta_data\"\n",
    "image_folder = r\"E:\\SNN project\\data\\KinFaceW-II\\images\"\n",
    "\n",
    "preprocessed_pairs, labels = loadmat_data(meta_folder, image_folder)\n",
    "\n",
    "print(f\"Number of pairs loaded: {len(preprocessed_pairs)}\") \n",
    "print(f\"Sample label: {labels[0]}\") \n",
    "pair_sample = preprocessed_pairs[0]\n",
    "print(f\"Shape of first image: {pair_sample[0].shape}\") \n",
    "print(f\"Shape of second image: {pair_sample[1].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8dd692-d7c2-4209-92c1-45b10eecf3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'pairs'])\n",
      "[[array([[1]], dtype=uint8) array([[1]], dtype=uint8)\n",
      "  array(['fd_240_1.jpg'], dtype='<U12')\n",
      "  array(['fd_240_2.jpg'], dtype='<U12')]\n",
      " [array([[1]], dtype=uint8) array([[1]], dtype=uint8)\n",
      "  array(['fd_024_1.jpg'], dtype='<U12')\n",
      "  array(['fd_024_2.jpg'], dtype='<U12')]\n",
      " [array([[1]], dtype=uint8) array([[1]], dtype=uint8)\n",
      "  array(['fd_220_1.jpg'], dtype='<U12')\n",
      "  array(['fd_220_2.jpg'], dtype='<U12')]\n",
      " ...\n",
      " [array([[5]], dtype=uint8) array([[0]], dtype=uint8)\n",
      "  array(['fd_089_1.jpg'], dtype='<U12')\n",
      "  array(['fd_100_2.jpg'], dtype='<U12')]\n",
      " [array([[5]], dtype=uint8) array([[0]], dtype=uint8)\n",
      "  array(['fd_041_1.jpg'], dtype='<U12')\n",
      "  array(['fd_123_2.jpg'], dtype='<U12')]\n",
      " [array([[5]], dtype=uint8) array([[0]], dtype=uint8)\n",
      "  array(['fd_224_1.jpg'], dtype='<U12')\n",
      "  array(['fd_017_2.jpg'], dtype='<U12')]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "mat_path = r\"E:\\SNN project\\data\\KinFaceW-II\\meta_data\\fd_pairs.mat\"  # Replace with one .mat file\n",
    "data = loadmat(mat_path)\n",
    "\n",
    "print(data.keys())  # List all keys in the .mat file\n",
    "print(data['pairs'])  # Inspect the 'pairs' field to understand its structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e4dfc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN_ARCHITECTURE(nn.Module): # inheriting from base class nn.Module\n",
    "  def __init__(self):   #initializer of this class\n",
    "    super(SNN_ARCHITECTURE,self).__init__() #calling the initializer of the base class\n",
    "\n",
    "    self.cnn = nn.Sequential(                                            # 2 convolutional layers\n",
    "    nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "    self.fc = nn.Sequential(                           # two fully connected layers\n",
    "      nn.Linear(64 * 28 * 28, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, 128)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.cnn(x)\n",
    "    x=torch.flatten(x,1)\n",
    "    x = self.fc(x)\n",
    "    return x\n",
    "  \n",
    "  def Euclidean_distance(self, image_1, image_2):\n",
    "\n",
    "    embed_1=self.forward(image_1)\n",
    "    embed_2=self.forward(image_2)\n",
    "    euclidean_distance = F.pairwise_distance(embed_1, embed_2)\n",
    "\n",
    "    return euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba17584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_Fxn(nn.Module):\n",
    "    def __init__(self,margin=1.5):\n",
    "        super(Loss_Fxn, self).__init__()\n",
    "        self.margin=margin\n",
    "\n",
    "    def forward(self, euclidean_distance, label):\n",
    "        Contrastive_loss =0.5*label*(euclidean_distance)**2+(1-label)*torch.clamp(self.margin-euclidean_distance, min=0)**2\n",
    "        return torch.mean(Contrastive_loss) #Contrastive_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "776a5fd9-54c3-4f99-8c51-93447a224e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images loaded: 2000\n",
      "Names: {'father-dau', 'mother-dau', 'father-son', 'mother-son'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images, names = IMG_Loading(\"E:\\SNN project\\data\\KinFaceW-II\\images\")\n",
    "    \n",
    "print(f\"Number of images loaded: {len(images)}\")\n",
    "print(f\"Names: {set(names)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36fa39a0-1bae-40c8-a74b-7855be1ca318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parent-child pairs created: 1000\n",
      "Sample pair labels: [1]\n"
     ]
    }
   ],
   "source": [
    "parent_child_pairs, pair_labels = Parent_child_pair(images_preprocessed)\n",
    "\n",
    "print(f'Number of parent-child pairs created: {len(parent_child_pairs)}')\n",
    "print(f'Sample pair labels: {pair_labels[:1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
